{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIkGvMglTRhT",
        "outputId": "a6e94ac3-9e74-4135-a7b3-51d0d44b9c47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin    cuda\tcuda-11.8  games\t       include\tlib64\t   man\t share\n",
            "colab  cuda-11\tetc\t   _gcs_config_ops.so  lib\tlicensing  sbin  src\n"
          ]
        }
      ],
      "source": [
        "! ls /usr/local/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pSfQ59STUF3",
        "outputId": "92c779af-5216-4945-dbe6-3c56080409d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "! nvcc --version # nvcc compiler version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile VectorAddition.cu\n",
        "#include<stdio.h>\n",
        "#include<time.h>\n",
        "#include<stdlib.h>\n",
        "#include<cuda_runtime.h>\n",
        "\n",
        "// Kernel Function - GPU function that is meant to be called from CPU code\n",
        "__global__ void VectorAddition(float *c_d, float *a_d, float *b_d, int N){\n",
        " int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        " if (idx<N){\n",
        "  c_d[idx] = a_d[idx] + b_d[idx];\n",
        " }\n",
        "}\n",
        "\n",
        "// Main code executed by the host\n",
        "int main(void){\n",
        "  float *a_h, *b_h, *c_h; // pointers host\n",
        "  float *a_d, *b_d, *c_d; // pointers device\n",
        "  const int N = 24; // No. of elements in arrays\n",
        "\n",
        "  size_t size=N * sizeof(float);\n",
        "\n",
        "  a_h = (float *)malloc(size);\n",
        "  b_h = (float *)malloc(size);\n",
        "  c_h = (float *)malloc(size);\n",
        "\n",
        "  srand(time(NULL));\n",
        "  for(int i = 0; i < N; i++){\n",
        "    a_h[i] = rand() % 100 + 1.0;\n",
        "    b_h[i] = rand() % 100 + 1.0;\n",
        "  }\n",
        "\n",
        "  printf(\"\\nArray a:\\n\");\n",
        "  for(int i = 0; i < N; i++) printf(\"%f \", a_h[i]);\n",
        "  printf(\"\\nArray b:\\n\");\n",
        "  for(int i = 0; i < N; i++) printf(\"%f \", b_h[i]);\n",
        "\n",
        "  cudaMalloc((void **) &a_d, size);\n",
        "  cudaMalloc((void **) &b_d, size);\n",
        "  cudaMalloc((void **) &c_d, size);\n",
        "\n",
        "  cudaMemcpy(a_d, a_h, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(b_d, b_h, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  int block_size = 8;\n",
        "  int n_blocks = N/block_size + (N%block_size == 0 ? 0:1);\n",
        "\n",
        "  VectorAddition<<<n_blocks, block_size>>>(c_d, a_d, b_d, N);\n",
        "\n",
        "  cudaMemcpy(c_h, c_d, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  printf(\"\\nArray c:\\n\");\n",
        "  for(int i = 0; i < N; i++) printf(\"%f \", c_h[i]);\n",
        "\n",
        "  free(a_h);\n",
        "  free(b_h);\n",
        "  free(c_h);\n",
        "\n",
        "  cudaFree(a_d);\n",
        "  cudaFree(b_d);\n",
        "  cudaFree(c_d);\n",
        "\n",
        "  return(0);\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOo2ffh2UJXK",
        "outputId": "9dd602a6-1e67-4c2a-b3f1-a9bc7d88b327"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting VectorAddition.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! nvcc VectorAddition.cu -o test"
      ],
      "metadata": {
        "id": "Ivzdi--2X2R_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIkJY9cIX6iJ",
        "outputId": "dfe94fad-b3d6-4abc-9207-82c59ca195a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Array a:\n",
            "7.000000 6.000000 73.000000 83.000000 2.000000 80.000000 79.000000 75.000000 71.000000 33.000000 28.000000 73.000000 73.000000 19.000000 93.000000 12.000000 54.000000 8.000000 69.000000 42.000000 41.000000 87.000000 65.000000 14.000000 \n",
            "Array b:\n",
            "70.000000 57.000000 1.000000 65.000000 100.000000 65.000000 92.000000 91.000000 77.000000 99.000000 43.000000 67.000000 94.000000 83.000000 33.000000 51.000000 69.000000 26.000000 42.000000 23.000000 74.000000 71.000000 13.000000 88.000000 \n",
            "Array c:\n",
            "77.000000 63.000000 74.000000 148.000000 102.000000 145.000000 171.000000 166.000000 148.000000 132.000000 71.000000 140.000000 167.000000 102.000000 126.000000 63.000000 123.000000 34.000000 111.000000 65.000000 115.000000 158.000000 78.000000 102.000000 "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}